#### Perceptron
A single layer neural network is called a perceptron which is used for binary classification
It is a function of f( bias plus the weighted sum)
The activation function/decision function is resulted from the output of the perceptron

$$f \left ( b + \sum_{i=1}^n x_{i}w_{i} \right )$$
- Non-linear activation functions introduce non-linearity 
#### Softmax
outputs the probability of each class, converts to a distribution. argmax then gets the highest value

##### Why do Neural Networks Work?
A neural network can approximate any continuous function using one hidden layer (Universal Approximation Theorem).